\documentclass{article}
\usepackage{inconsolata}
\usepackage[T1]{fontenc}
% ^ Somehow is able to fix libertine's bold font
\usepackage[tt=false]{libertine}
% \usepackage[libertine, cmintegrals]{newtxmath}
\usepackage{microtype}
\usepackage{hyperref}
\usepackage[intoc]{nomencl}
\makenomenclature

% Graph
\usepackage{dot2texi}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}
% \usepackage{indentfirst}

\begin{document}
\title{Kotlin Compiler Reading Notes}
\author{Yuxiang Jiang \thanks{yxjiang@linkedin.com}}
\maketitle

% Commands
\newcommand{\textSafeTo}{\texorpdfstring{$\to$}{to} }
% End commands

\tableofcontents
\clearpage

\section{Methodology}
It's often daunting to read through huge and complex codebase like \href{https://github.com/JetBrains/kotlin}{the Kotlin compiler}! Fortunately we have great tools at hand to deal with such complexity. In particular, IntelliJ Idea provides many priceless code navigation tools:
\begin{itemize}
    \item Type Hierarchy (under Navigate)
    \item Structure (under View - Tool Windows)
    \item Find Usage
    \item Breakpoints
\end{itemize}

With these we'll be able to understand the compiler architecture and internals bit by bit...

\subsection{Building From Source}
Once you have the repo checked out, run \texttt{./gradlew dist} to build everything. This can take 10-20 minutes. Then you will be able to run tests, compiler.cli.cli-runner (i.e. the script runner), and compiler.preloader (i.e. the CLI compiler loader).

\subsection{Tracing Compiler Execution}

It's often useful to use the debugger to understand how the compiler pipeline works. This requires the ability to run custom code and to attach a debugger to the compiler process. One trick that I used was to add a local file to the cli-runner package (or compiler.preloader). This allows me to run or debug arbitrary code there while being able to link the code with the compiler. And since these these packages don't actually have source dependency on the whole compiler (only link to the dist jar), rebuilding is quite fast.

Another way is to link your code with a prebuilt compiler (e.g. add dependency \texttt{"org.jetbrains.kotlin:kotlin-compiler:1.3.70"}). I can't seem to fetch its sourceJar though...

\section{Tl;dr: Pipeline}

The are couple key types in the compiler pipeline:

\begin{itemize}
    \item KtElement (Psi): concrete syntax tree, backed by JetBrain's Psi system for wonderful IDE integration.
    \item core.descriptor, BindingContext, and friends: results of various frontend analysis: type checking, method binding, etc.
    \item FIR (FirElement etc): ``Frontend IR", seems to be a new IR that's converible from Psi.
    \item IR (IrSymbol, IrDeclaration): Experimental backend IR.
\end{itemize}

Here's a call graph for the script evaluator and the CLI compiler:
\begin{dot2tex}[dot,scale=0.3]
\input{arch-diagram.dot}
\end{dot2tex}

\section{KtElement (Psi)}

This is the concrete syntax tree of Kotlin.

\begin{itemize}
    \item See class KtVisitor for an overview of many Kotlin PsiElements
    \item KtFile and KtScript for toplevel containers
    \item KtClass for \texttt{class Foo}, KtNamedFunction for \texttt{fun foo()}, KtProperty for \texttt{val foo}.
    \item compiler.psi defines KtElement and \href{https://www.jetbrains.org/intellij/sdk/docs/basics/indexing_and_psi_stubs/stub_indexes.html}{Stubs}, also provides parser
    \begin{itemize}
        \item Stubs represents the interface parts of a kt compilation unit
        (.h, .mli, .hi etc).
        \item There's also a LighterASTNNode (KotlinLightParser) -- what is it? (Flyweight pattern is like hash consing)
        \item Some KtElements are related to types: e.g. KtTypeReference (some of them are not KtElements but stubs!)
    \end{itemize}
    \item compiler.psi.KtPsiFactory is the entrypoint for creating KtFile (a PsiElement) from source text.
\end{itemize}

\section{DeclarationDescriptor}
\label{sec:descriptor}

See core.descriptors.DeclarationDescriptorVisitor for an overview.

DeclarationDescriptorVisitor sounds like an type-instantiated/abstracted wrapper of an element. Also has a bunch of annotations (AnnotationDescriptor) and a name. And is also a tree node (has parent: getContainingDecl)

\subsection{Survey of Class Hierarchy}

Looks that descriptors are something that's used throughout the whole compilation pipeline. They are more often used in frontend, but even in backend I can see some usage of them.

\subsubsection{CallableD: VisD \& NonRootD \& Subst}

Receiver types (dispatch / extension), arg types, return types, type params;

Parameter names, names may be unstable/synthesized (e.g. from JVM object code)

Parameter values (See \ref{sec:ValueParamD})

Cross ref to overridden methods.

UserDataKey$<$A$>$: stores typed user data

\subsubsection{MemberD: VisD \& NonRootD}

Has member modifiers: expect / actual / external. And modality: final /sealed / open / abstract.

\subsubsection{CallableMemberD: CallableD \& MemberD}

Kind: decl / delegation / fakeOverride / synthesized (what's the last two?)

\subsubsection{ValueD: CallableD}

Has a KotlinType.

\subsubsection{VarD: ValueD}

Has isVar (wat), isLateinit, isConst, and an optional compileTimeInitializer.

\subsubsection{ParamD: ValueD}
Represents a parameter that can be supplied to a callableD.

\paragraph{ReceiverParamD: ParamD}
Has a ReceiverValue.

\paragraph{ValueParamD: ParamD \& VarD}
\label{sec:ValueParamD}
Has a index, hasDefaultValue, varargElementType, isCrossinline / Noinline (why on param?)

\subsubsection{VarDWithAccessors}

Has optional getter / setter typed VarAccessorD.

\subsubsection{FunD: CallableMemberD}

initialSignatureD: the initial D before renaming (didn't find SimpleFunctionD.rename)

hiddenToOvercomeSignatureClash: hack to handle corner case signature clash (said see nio.CharBuffer); also hiddenEverywhereBesideSupercalls: see \ref{sec:FunDImpl-hidden}.

Function modifiers: infix/inline/operator/suspend/tailrec

\subsubsection{FunDImpl: NonRootDImpl \& FunD}

Base impl for function modifiers. Setters set the local modifier (mostly happen during conversion from KtElement), while some getters (infix, operator) respect super class methods.

Base impl for substitution (doSubstitute), and substituted value param. Worth reading.

Base impl for initialize.

\label{sec:FunDImpl-hidden}
Only here documents hiddenToOvercomeSignatureClash and hiddenEverywhere-BesideSupercalls: former makes the function completely hidden (even in super-call), latter permits super-call and propagates to overriden methods

\subsubsection{ConD: FunD}

containingD: ClassifierDWithTypeParams (what is this?)

constructedClass: ClassD

\subsubsection{ClassConD: ConD}

Just a bunch of return type specializations

\subsubsection{ClassConDImpl: FunDImpl \& ClassConD}

Default (\texttt{<init>}) or synthesized.

Has a way to calculate dispatchReceiverParam. If inner, init's receiver is outer class instance (Whereas Java's outer class instance is passed as a param. Though in compiled code there's no difference, just at descriptor level they are different.); else null.

\paragraph{CommonizedClassConD: ClassConDImpl}
ClassConDImpl with source and originalD stripped.

\paragraph{DefaultClassConD: ClassConDImpl}
Read as (default constructor) of given class, not default implementation of (any class constructor). So this is just the no-param constructor of a class. Its visibility depends on the classD's visibility.

\paragraph{DeserClassConD: ClassConDImpl \& DeserCallableMemberD}
ProtoBuf based deserialized ClassConD. Holds a bunch of TypeTable, NameResolver, ContainerSource etc to help with further deserialization (so this is also in some sense lazy).

\paragraph{JClassConD: ClassConDImpl \& JCallableMemberD}
A Java imported class's constructor. Since this is from JVM object code, it provides property impl of hasStableParamNames / hasSynthesizedParamNames.

enhance() implementation makes a copy with enhanced receiver param and value params.

\paragraph{SamAdapterClass: ClassConDImpl \& SamAdapterD$<$JavaClassConD$>$}
A synthetic ClassConD that wraps another ClassConD.

\subsection{DFactory}

In core.descriptors / resolve.

\section{FIR}
\label{sec:fir}

Front-end IR (not sure what this means), enabled by \texttt{-Xuse-fir} (This also implies using IR. But use-ir doesn't imply using FIR). The flag doc says it's in very early stage of development though.

compiler.fir.resolve: ResolutionStage sounds like something pipeline-related

\subsection{Some observations}

\begin{itemize}
    \item See generated class FirVisitor for an overview of many of the Fir exprs
    \item compiler.frontend (not sure which step it is in, but it at least does symbol resolution, type checking, (Psi \textSafeTo CFG?)
    \begin{itemize}
        \item See key classes: AnalysisResult, BindingContext, BindingTrace (records the collected binding / type substs?)
    \end{itemize}
    \item compiler.resolution: tower/ReceiverValue etc
    \item compiler.fir: cones (types and symbols used in Fir?), fir2ir (lowering to Ir), psi2fir (lowering Psi to Fir), resolve, jvm, tree (Fir definitions and impl for psi2fir)
    \begin{itemize}
        \item cones: StandardClassIds contains a bunch of core Kt (read: not JVM) type Ids. They have a JVM-like fqname.

        SyntheticCallableId contains when/try/nullcheck synthetic call exprs

        \item tree.gen contains all Fir expressions (see tree.tree-generator's readme for how they are generated), as well as extra info (FirTypeRef). And even on Fir level, the generic types are not yet erased (FirTypeProjectionWithVariance)
    \end{itemize}
\end{itemize}

\section{IR}
\label{sec:ir}

IR (compiler.ir) seems to be an lower-level IR. This is an experimental IR that's intended to be used across all Kotlin backends. Also see \href{https://medium.com/@bnorm/exploring-kotlin-ir-bed8df167c23}{this writeup}.

A sample IR lowering pass can be found \href{https://github.com/JetBrains/kotlin/blob/936e53d/compiler/ir/backend.common/src/org/jetbrains/kotlin/backend/common/lower/TailrecLowering.kt}{here}. Looks that the compiler API provides a convenient IrBuilder, and a visitor style IrTransformer.

\subsection{Playing with IR}
This is enabled by passing \texttt{-Xuse-ir} as a CLI option to the compiler. IR backend currently doesn't support the script runner -- KotlinToJVMBytecodeCompiler will ignore use-ir on kts files; Also ScriptCodegen calls KotlinTypeMapper.mapType which is not intended to be called with IR backend.

\subsection{compiler.ir.tree}
IrSymbol definitions. See IrSymbolVisitor for an overview. Looks that they have descriptors attached.

\subsection{Phases}
compiler.ir.backend.common defines CompilerPhase that's chainable. See PhaseBuilders.kt and JvmLower.kt.

\subsection{IrSymbol vs IrElement}
IrElement seems to be the implementation part while IrSymbol is more about the declaration part. E.g. IrClassImpl vs IrClassSymbolImpl. The former contain the concrete class members (init, methods) while the latter contains ClassD.

IrSymbol can be bound or not (what does this mean?), has a owner (an IrElement), an IdSignature (what's this?), and visibility (isPublicApi).

\subsection{Psi \textSafeTo IR}

compiler.ir.ir.psi2ir contains Psi2IrTranslator, which sounds like the entrypoint for this convertion.

The translator contains an IdSignatureComposer, which composes IdSignature from DeclarationDescriptor, and ClassD for enums.

package generator contains ThingGenerator that generates IrThing from KtThing. Generated IR will remember the KtElement's source position range (startOffset and endOffset).

\subsubsection{DeclarationGenerator}

Generates toplevel IrDecl from KtDecl. ``Toplevel" is a very minimal set of KtDecl: KtNamedFunc, KtProperty, KtClassOrObject, KtTypeAlias, and KtScript. The resulting IrDecl contains both the declaration and the body implementation.

\section{Type System}

\subsection{Types}

Kotlin compiler uses \href{https://en.wikipedia.org/wiki/Marker_interface_pattern}{Marker Interface pattern} extensively in type definitions. See TypeSystemContext.kt (KotlinTypeMarker, TypeArgumentMarket etc).

KotlinType is the base class for all types in Kotlin. It has a tycon, list of tyargs, nullability (so nullability is built-in to any type -- can this be problematic?). It also has a MemberScope (``what are the members in this type-based namespace?", see \ref{sec:reso}) and a refine(KotlinTypeRefiner) method.

\subsection{core.type-system}

type system core (equality, bounds checking etc). However this is more of an interface module -- the actual impls are in core.descriptors, fir and ir modules.

\subsection{TypeSystemTypeFactoryContext}

Contains a bunch of common type factories:

\begin{itemize}
    \item flexibleType has lower/upper bounds
    \item simpleType has tycon, tyargs, nullablep
    \item tyarg has ty and variance
    \item star has tyarg (why?)
    \item there's also an error type used in diagnosis
\end{itemize}

\subsection{TypeCheckerProviderContext}

\begin{itemize}
    \item modular axioms (errorType unifiable with all types etc)
    \item what is a stub type? (Probably PsiStub related?)
\end{itemize}

\subsection{TypeSystemCommonSuperTypesContext}

Used to check if two type has common super types, and lowest-common ancestor utils.

typeDepth is a safe overestimation of the depth (from `Any`).

Seems to also be used in Fir.

\subsection{TypeSystemInferenceExtensionContext}

Inference related.

\subsection{Type Checking During Analysis}

\subsubsection{ExpressionTypingServices} Seems to be the entrypoint, which creates an ExpressionTypingContext and calls ExpressionTypingVisitorDispatcher.getTypeInfo.

\subsubsection{ExpressionTypingVisitorDispatcher} A delegating KtVisitor with context ExpressionTypingContext and returns KotlinTypeInfo.

Delegates its visiter methods to a bunch of sub-visitors: functions, control structures, patterns, basic expressions, and annotations/declarations etc.

Handles DeferredType by retrying type checking after the statement visitor returns.

\subsubsection{ExpressionTypingVisitorForStatements} An ExpressionTypingVisitor for statements (XXX how can statements have types?).

\paragraph{.visitBinaryExpression}
Handles eq, add-eq, and other binary ops.

Take visitAssignment for example. So first it creates a new ResolutionContext with overridden expected type, scope, and context dependency.

Then it check lhs: Lhs can have annotation, which it resolves. Lhs can also be arrayAccess, which it handles in another way (BasicExpressionTypingVisitor-resolveArrayAccessSetMethod then checkLValue).


\subsubsection{Questions}
\begin{itemize}
    \item What is a isCapturedTypeConstructor?
    \item What is a singleBestRepresentative?
    \item What is a noInferAnnotation?
    \item What is mayBeTypeVariable?
    \item What is a defaultType?
    \item Read impl of isUnit vs isUnitTypeConstructor
    \item Read impl of createCapturedType
    \item Read impl of createStubType
    \item Read impl createEmptySubstitutor, typeSubstitutorByTypeConstructor, safeSubstitute
\end{itemize}

\subsection{TypeSystemContext}

\begin{itemize}
    \item fastCorrespondingSupertypes has no actual impl? (No, it's just that intellij's search functionality fail to find overridden extension methods)
    \item isCommonFinalClassConstructor is implemented in three (Psi, Fir, Ir) stage's TypeSystemContext:
    \begin{itemize}
        \item ClassicTypeSystemContext: get ClassDescriptor from TypeConstructor's declarationDescriptor, then check it's final but not (enum or annotation). So the method really checks that the tycon is ``final" but is not a uncommon (enum/annotation) class.
        \item ConeTypeContext: Does almost the same thing, but also return true if is anonymous object (final by design). Works on FirBasedSymbol (some sort of class infotable?). Check that this is a FirRegularClassSymbol, whose FirRegularClass is final but not uncommon.
        \item IrTypeSystemContext: Check this is a IrClassSymbol whose owner is final and not uncommon.

        So basically ClassDescriptor, FirRegularClass and IrClassSymbol.owner are the same thing across three stages.

        Sounds that reading the common implemented methods of these three TySysCtx impl classes would be super helpful to understand the stages.
    \end{itemize}
\end{itemize}

\subsection{Playing with Types}

DescriptorRenderer.SHORT\_NAMES\_IN\_TYPES.renderType could be used to render KotlinType.

KotlinTypeChecker.DEFAULT could be used for simple type checking (equality, subtype relationship etc)

\subsection{Type System for Fir}

Read ConeTypeContext

\subsection{Type System for Ir}

Read IrTypeSystemContext

\subsection{compiler.resolution/.inference}

Type inference? constraint system, subst, fresh tycon, tyvar etc

\subsection{compiler.frontend/.types}

TypeIntersector (unify), DeferredType (I guess this is for when inference can't proceed at some first, and will retry when it has more information. Not really fully bidirectional (H-M style) type inference, but an approximation)

\subsection{types.expressions}

Contains a bunch of KtElement visitors that does type recon/checking:
\begin{itemize}
\item ExpressionTypingVisitorDispatcher
\item ControlStructureTypingVisitor
\item FunctionsTypingVisitor
\item BasicExpressionTypingVisitor (constants etc)
\begin{itemize}
  \item This actually does a bit of parsing/validation work... e.g. understore on int literals.
  \item Also uses ConstantExpressionEvaluator to check for possible compile time constants (this indeed sounds like something a parser would do).
  
  Folds boolean \texttt{\&\&} and \texttt{||}

  Look up simple unary and binary func in OperationsMapGenerated
\end{itemize}
\end{itemize}

\section{Resolution}
\label{sec:reso}

Package: compiler.frontend and compiler.resolution (specific types)

\subsection{ResolutionContext}

Kotlin compiler does data flow analysis in a top-down fashion. This class is used to pass data flow analysis results from AST parent to its children.

Known concrete subtypes: ExpressionTypingContext, CallCandidateResolutionContext, CallResolutionContext.

\subsection{Scopes}

core.descriptor / ResolutionScope: contains information about what identifier it contributes to a given lookup location. Identifiers have separate namespaces: variable, function, and classifier (type).

compiler.resolution / LexicalScope is a ResolutionScope that has a parent, a ownerD, a LexicalScopeKind (what kind of syntactical structure created this scope?)

\subsection{Tower}

i.e. ImplicitScopeTower. Some sort of multi-level scopes? Can't understand this part.

\section{Analysis}

Package: compiler.frontend. There are various analysis done in the frontend: Psi to DeclarationDescriptor, control flow graph (package cfg), type checking, method resolution (package resolve)...

This is a very complicated process -- later stages depend on the result of the early stages. Information are passed either directly, or in the form of a shared mutable context (BindingTraceContext, TopDownAnalysisContext etc).

It would be extremely useful to understand the input and the output of each analysis stage! Unfortunately due to that the pipelines share results via mutable data, we won't know this by simply looking at their return types. Instead we have to read the implementation of each stage to see what they use.

\subsection{compiler.cli.TopDownAnalyzerFacadeForJVM}

Creates a DI container for all the components used throughout the analysis process, then call into LazyTopDownAnalyzer.

\subsection{compiler.frontend.LazyTopDownAnalyzer}

compiler.frontend.LazyTopDownAnalyzer contains the whole analysis pipeline: it ultimately converts Psi into DeclarationDescriptor. (Is there another analyzer that's not lazy?)

\paragraph{analyzeDeclarations}

analyzeDeclarations returns an AnalysisResult which contains a ModuleDescriptor and a BindingContext.

It goes through all stmts, calls:
\begin{itemize}
    \item A bunch of resolvers: BodyResolver.resolveBodies, LazyDeclarationResolver etc.
    \item DeclarationsChecker.process, which goes through files, annotations, class's modifiers, idents, header (super+generic bounds); function, property, destructionDecl, typealias's modifiers and idents.
\end{itemize}

\subsubsection{BodiesResolveContext}

Stores the toplevel declarations (in typed maps) found during analysis. Concrete implementation: TopDownAnalysisContext, created in LazyTopDownAnalyzer.

\subsubsection{ThingResolver}
E.g. LazyDeclarationResolver. They have a .trace that is a LockProtectedTrace (under LockBasedLazyResolverStorageManager). The real trace is NoScopeRecordCliBindingTrace (i.e. doesn't records scope information).

\subsection{BindingTrace}
Has a BindingContext. Is writable. Can record/inquiry KotlinType for a KtElement.
Impls: BindingTraceContext and ObservingBindingTrace

\subsubsection{BindingContext}

Sounds like a read-only counterpart to the BindingTrace.

\subsubsection{BindingTraceContext}
Concrete implementation of BindingTrace. Has a map: SlicedMapImpl.

\paragraph{SlicedMapImpl} This is a two-level map: .map maps a key (e.g. a KtElement) to a holder: KeyFMap. The holder takes a slice.key (usually the key is the slice itself) and return the value (e.g. a DeclarationDescriptor).

\paragraph{KeyFMap} An abstract immutable map. But it's not backed by any purely functional data structures... (See impl: OneElementFMap, ArrayBackedFMap etc)

\paragraph{Slice}
A Slice$<$K, V$>$ is an identifier for a mapping from K to V. Such mapping often represents the analysis results (e.g. what's the DeclarationDescriptor of this KtElement?). See BindingContext.java for a list of all the common slices.

\subsection{KotlinCodeAnalyzer}
See concrete impl ResolveSession.

\subsection{DeclarationChecker}

Check a KtDecl against a DeclarationDescriptor within a DeclarationCheckerContext. Has lots of subtypes. Reports errors to context's BindingTrace. Some checkers are just linters that enforce certain code style. Others are necessarily to ensure soundness.

PlatformConfiguratiorBase contains a bunch of linter-like checkers.

\subsection{Control Flow Analysis}

package: cfg. Looks like traditional control flow analysis (not PDG). Nodes are represented by class Instruction -- it has def-use chain (class PseudoValue), prev/succ edges, and is implemented by lots of concrete instructions. See InstructionVisitor for a list of concrete instrs.

\paragraph{PseudoCode} Looks like basic block but maybe not. Groups the instructions. Can be nested.

\paragraph{ControlFlowAnalyzer}

Entrypoint of control flow analysis. Its .process method checks BodiesResolveContext's files, classes, function, and properties.

\paragraph{ControlFlowProcessor}

Converts a KtElement (with the its BindingTrace) to a PseudoCode.

\paragraph{ControlFlowBuilder}

Concrete impl: ControlFlowInstructionsGenerator. Used by ControlFlowProcessor, knows how to generate individual instructions (i.e. How to map a KtParameter to a VariableDeclInstruction?). Also holds the context of the current graph.

\paragraph{ControlFlowInformationProvider}

Does real work (e.g. checkDeclaration) to analyze the control flow. E.g. checkFunction will make sure a function with a non-unit return type always returns something. Records a few flow related things: MUST\_BE\_LATEINIT etc.

\subsubsection{Survey of CFG Instructions}

\paragraph{Subroutine\{Enter,Exit,Sink\}Instruction} Well known nodes for function start and end. Sounds that Exit is for returns / exceptions, and Sink is the unique end of the graph?

\subsection{Smartcasting}

compiler.frontend smartcasts.DataFlowInfo: bunch of maps to stores the data flow analysis result useful for smart casts.

DataFlowValue: one instance of a value in a dataflow

DataFlowValue.Kind: classify exprs into smart cast enabled, possible, or disabled ones. Quite intuitive.

IdentifierInfo: represents both qualifier and ident name. what is this for?

\section{Codegen}

There are currently two codegen systems and both target JS, JVM, etc. They differ in the choice of IR.

\begin{itemize}
    \item The existing production codegen uses KtElement (Psi node) as the IR. JVM codegen lives in compiler.backend / codegen (e.g. ClassBodyCodeGen); JS codegen lives in js.js.translator (e.g. PropertyTranslator).
    \item The other ``experimental" codegen uses compiler.ir as the IR. All targets specific code lives in compiler.ir.backend.TARGET.
\end{itemize}

\subsection{Psi-based Codegen}

\subsubsection{JVM}

\paragraph{ExpressionCodeGen}
Generates JVM bytecode directly from KtElement. This is a KtVisitor$<$StackValue$^2$$>$. Has an InstructionAdapter (JVM bytecode emitter).

\paragraph{StackValue}
Sounds like a helper class to represent operands on the JVM stack. Has a couple subclasses.

\paragraph{ClassBodyCodeGen}
Generate class body from a KtPureClassOrObject with a ClassDescriptor. Also does bridge generation.

\paragraph{FunctionCodeGen}
Generate class body from a KtPureClassOrObject with a ClassDescriptor. Also does bridge generation.

\subsubsection{JS}

e.S. js.js.translator / PropertyTranslator. Looks that it directly translates descriptor + Psi (KtElement) into JS statement / expressions.

Also see FunctionBodyTranslator -- takes a FunD and a KtElement (KtDeclWithBody).

\subsection{IR-based Codegen}

\subsubsection{JVM}

\paragraph{ClassCodegen}
Takes an IrClass and generates into a JvmBackendContext.

\section{Compiler Plugin}

\subsection{Case study: All Open}

The \href{https://kotlinlang.org/docs/reference/compiler-plugins.html}{all-open plugin} marks all classes annotated with some annotations to have the open modality. The implementation of the plugin lives in the Kotlin compiler repo and is easy to understand.

The plugin has a couple components: core (Kt compiler plugin), gradle plugin, and IDE plugin.

\subsubsection{plugins.allopen.allopen-cli}

Core implementation: the actual plugin (called extension), plugin registrar, and cli option processor.

\paragraph{AbstractAllOpenDeclarationAttributeAltererExtension} Implements DeclarationAttributeAltererExtension which has a refineDeclarationModality method that overrides the modality of some declarations.

\paragraph{AllOpenCommandLineProcessor} Read CLI options and store them as typed configuration keys. The options will be consumed by the registrar.

\paragraph{AllOpenComponentRegistrar} Registers the extension as a Kotlin compiler plugin. Also see resource/META-INF/services for service discovery.

\subsection{Plugin API}

The plugin API is currently under changes -- Some of the extensions that deal with type checking and call resolution are marked as unsable (e.g. InternalNonStableExtensionPoints) but jetpack-compose uses these.

Plugins are integrated to the compiler all over around the pipeline: some are used in frontend, some are used in backend.

\paragraph{ProjectExtensionDescriptor} Knows how exactly to register an extension, and how to find one. Each extension has an instance of this to register itself.

\paragraph{DeclarationAttributeAltererExtension} A frontend extension. Is used in ModifiersChecker to override modalities.

\paragraph{ExpressionCodegenExtension}
A backend extension. The noarg plugin uses this. 

\paragraph{AnalysisHandlerExtension}
A Java frontend extension. Maybe it can help with overriding types?

\section{Scratch}

\subsection{Questions}

\begin{itemize}
    \item What is a LazyTypeParameterDescriptor?
    \item What is a core.descriptors.MemberScope?
    \item What's the diff between TypeCheckerContext and TypeSystemContext?
\end{itemize}

\subsection{Stack traces}

\subsubsection{Pipeline for \texttt{kotlin} Script Runner}
Note that the runner uses coroutine in its eval methods and therefore can be hard to trace.

Runner: AbstractScriptEvaluationExtension \textSafeTo ScriptJvmCompilerImpls
Parse: jvmCompilationUtil.getScriptKtFile: text-based Kt source \textSafeTo KtFile (Psi-based KtElement)
Analysis: TopDownAnalyzerFacadeForJVM \textSafeTo LazyTopDownAnalyzer
Codegen (Psi-based): KotlinCodegenFacade \textSafeTo DefaultCodegenFactory \textSafeTo THINGCodegen (e.g. Package / Member / Script / ImplementationBody / ClassBody)
Eval: AbstractScriptEvaluationExtension \textSafeTo BasicJvmScriptEvaluator

\subsubsection{Pipeline for \texttt{kotlinc} Compiler}

 Runner: compiler.preloader / Preloader \textSafeTo compiler.cli / K2JVMCompiler \textSafeTo KotlinToJVMBytecodeCompiler (checks IR flag)
Parse: Not sure
Analysis: KotlinToJVMBytecodeCompiler.analyze \textSafeTo TopDownAnalyzerFacadeForJVM
Codegen (Psi-based): KotlinToJVMBytecodeCompiler.generate \textSafeTo KotlinCodegenFacade
Lowering (Ir-based): analysis is the same; but ktjvmbcc.generate is different? Uses JvmIrCodeGenFactory with a PhaseConfig. I.e., .generate \textSafeTo JvmIrCodeGenFactory \textSafeTo JvmBackendFacade \textSafeTo JvmLower \textSafeTo CompilerPhase.invokeToplevel(PhaseConfig, JvmBackendContext, IrModuleFragment) \textSafeTo a bunch of abstraction layers around lowering phases \textSafeTo SomeLoweringPass.lower
Codegen (Ir-based): JvmBackendFacade \textSafeTo ClassCodeGen (IrFile.declarations should only contain IrClass after lowering)
Write: KotlinToJVMBytecodeCompiler.writeOutputs

\subsubsection{Pipeline for Analysis}

LazyTopDownAnalyzer.analyzeDeclarations \textSafeTo lots of resolvers and checkers.
BodyResolver.resolveBodies: resolve behavior decl bodies (what is a behavior decl?), build CFG, check declarations, run extension checkers.

Looks that at least BodyResolver.resolveBehaviorDeclarationBodies does type checking. E.g. resolveFunctionBodies checks expression types in function bodies, using ExpressionTypingServices.

CFG depends on DeclarationDescriptors built from a previous step (See ControlFlowInformationProvider). Also seems to depend on method calls being resolved (See CFP (generateArrayAssignment) -- at least for INDEXED\_LVALUE\_SET).

\begin{itemize}
    \item INDEXED\_LVALUE\_\{GET,SET\} (e.g. \texttt{arr[ix] = val}): recorded in BasicExpressionTypingVisitor (resolveArrayAccessSpecialMethod). This is interesting -- It suggests that expression type checking and resolution are done in the same place.
\end{itemize}

There's a CFG to Dot graph printer: CFGraphToDotFilePrinter. It sounds useful to visualize the CFG, but it's in tests-common.

\input{nomenclature.tex}
\newpage
\printnomenclature

\end{document}
